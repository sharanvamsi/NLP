{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk import word_tokenize\n",
    "from collections import defaultdict\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete(train):\n",
    "    del train['location']\n",
    "    del train['keyword']\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete(train)\n",
    "delete(test)\n",
    "y_train=train.iloc[:,-1]\n",
    "x_train=train.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemm = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing a comprehensive list of stopwords from GITHUB, make sure to cite when writing final report\n",
    "gist_file = open(\"gist_stopwords.txt\", \"r\")\n",
    "try:\n",
    "    content = gist_file.read()\n",
    "    stopwords = content.split(\",\")\n",
    "finally:\n",
    "    gist_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwordremoval(text):\n",
    "    return \" \".join([w for w in str(text).split() if w not in stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Our Deeds are the Reason of this earthquake Ma...\n",
       "1                Forest fire near La Ronge Sask Canada\n",
       "2    All residents asked to shelter in place are be...\n",
       "3    13000 people receive wildfires evacuation orde...\n",
       "4    Just got sent this photo from Ruby Alaska as s...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing puncuation from text\n",
    "import string \n",
    "englishpunc = string.punctuation\n",
    "punctuations_list = englishpunc\n",
    "def punctuations(text):\n",
    "    translator = str.maketrans('', '', punctuations_list)\n",
    "    return text.translate(translator)\n",
    "train['text']= train['text'].apply(lambda x: punctuations(x))\n",
    "train['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_URLs(data):\n",
    "    return re.sub('((www.[^s]+)|(https?://[^s]+))',' ',data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = []\n",
    "def arraycreator(data):\n",
    "    data = data.lower()\n",
    "    array.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processdata(train):\n",
    "    train['text'] = train['text'].apply(lambda x: cleaning_URLs(x))\n",
    "    train['text'] = train['text'].apply(lambda x: stopwordremoval(x))\n",
    "    train['text']= train['text'].apply(lambda x: punctuations(x))\n",
    "    train['text'].apply(lambda x: arraycreator(x))\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = processdata(train)\n",
    "test = processdata(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv=TfidfVectorizer(max_features=8000)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 8000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_vector=cv.fit_transform(train).toarray()\n",
    "x_test_vector=cv.transform(test).toarray()\n",
    "x_train_vector = x_train_vector[:7613]\n",
    "x_train_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8690398003415211\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model=MultinomialNB()\n",
    "model.fit(x_train_vector,y_train)\n",
    "print(model.score(x_train_vector,y_train))\n",
    "y_pred1=model.predict(x_test_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6224878497307238\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc=RandomForestClassifier(random_state=4,n_estimators=500,warm_start=True,max_depth=6,min_samples_leaf=2,min_samples_split=3)\n",
    "rfc.fit(x_train_vector,y_train)\n",
    "print(rfc.score(x_train_vector,y_train))\n",
    "y_pred2=rfc.predict(x_test_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sharanvamsi/anaconda3/lib/python3.11/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8392223827663208\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb=XGBClassifier()\n",
    "xgb.fit(x_train_vector,y_train,early_stopping_rounds=5, \n",
    "             eval_set=[(x_train_vector,y_train)], \n",
    "             verbose=False)\n",
    "print(xgb.score(x_train_vector,y_train))\n",
    "y_pred3=xgb.predict(x_test_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8788913700249573\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "reg=LogisticRegression()\n",
    "reg.fit(x_train_vector,y_train)\n",
    "print(reg.score(x_train_vector,y_train))\n",
    "y_pred4=reg.predict(x_test_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9808222776829109\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "passive=PassiveAggressiveClassifier()\n",
    "passive.fit(x_train_vector,y_train)\n",
    "print(passive.score(x_train_vector,y_train))\n",
    "y_pred5=passive.predict(x_test_vector)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
